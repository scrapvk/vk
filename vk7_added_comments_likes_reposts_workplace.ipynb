{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vk\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opennig vk session with access token.\n",
    "session = vk.Session(access_token='0dfed272d8c2c0882f26fabaee86c1c23eca901348c1e8476f93a1fd83fe06b4b9fc4070f7c0f1aa269f6')\n",
    "api = vk.API(session)\n",
    "# example use with id, my id\n",
    "api.users.get(user_ids='architectofreality' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for a keyword glaukoma starting 48 hours ago, max 200 counts can be scrapped at once\n",
    "glaukoma=api.newsfeed.search(q='glaukoma',count=200, start_time=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get last 200 posts --> take the time of the last post --> at the next iteration set the end time = time_last_post-1. Set the start time to 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "glaukoma_rus=api.newsfeed.search(q='glaukoma',count=200, end_time=1512378120, start_time=1512378121-86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the first element and creat a dataframe with the rest\n",
    "df=pd.DataFrame(glaukoma_rus[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#getting info of each user, deactivated column\n",
    "ids=pd.DataFrame(api.users.get(user_ids=abs(df['owner_id'])))\n",
    "ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key_words = ['#глаза', \n",
    "             '#глазки', '#зрение', '#лечениезрения', '#детскоезрение', '#лечениеглаз',\n",
    "             '#офтальмолог','#офтальмология', '#офтальмохирург', '#офтальмохирургия', '#детскоезрение',\n",
    "             '#детскийофтальмолог', '#офтальмологмосква','#дакриоцистит', '#дакриоциститноворожденных',\n",
    "             '#дакриоциститмассаж','#дакриоциститлечение', '#дакриоцисториностомия', '#зондированиеносослёзногоканала',\n",
    "             '#зондированиеноворождённых','#нистагм', '#лечениенистагма','#нистагмоперация', '#нистагмъ',\n",
    "             '#близорукость', '#миопия', '#лечениеблизорукости', '#близорукостьнеприговор',\n",
    "             '#близоркостьлечение', '#близорукостьонатакая', '#близорукостьнепорок',\n",
    "             '#близорукостьудетей','#дальнозоркость', '#гиперметропия', '#лечениедальнозоркости',\n",
    "             '#дальнозоркостьлечение','#дальнозоркостьудетей', '#дальнозоркости','#косоглазие',\n",
    "             '#страбизм', '#лечениекосоглазия', '#косоглазиелечение', '#косоглазиеэтосексуально',\n",
    "             '#косоглазиебишкек', '#косоглазиенепорок', '#косоглазие дети', '#косоглазиеэтомодно',\n",
    "             '#астигматизм', '#астигматизмлечение', '#астигматизмудетей','#амблиопия', '#амблиопиявысокойстепени',\n",
    "             '#амблиопиямосква', '#катаракта','#катарактавладивосток', '#катарактачелябинск',\n",
    "             '#катаракта лечение москва','#катарактаоперация', '#глаукома', '#глаукомалечение', \n",
    "             '#глаукомавладивосток','#глаукомачелябинск', '#птоз', '#птозверхнеговека', '#птозвека',\n",
    "             '#птозвек', '#птозанет','#лазернаякоррекция', '#лазернаякоррекциязрения', '#лазернаякоррекциязрениямосква',\n",
    "             '#лазернаякоррекцияакция', '#лазернаякоррекциямосква', '#лазернаякоррекциязренияомикрон',\n",
    "             '#лазернаякоррекцияскидки', '#lasik', '#фрк', '#smile', '#ласик', '#ласикмосква', '#ячмень', '#халязион']\n",
    "desired_time = 86400*365 # how much back we want to go in seconds\n",
    "entire_df = pd.DataFrame()\n",
    "k = 1\n",
    "for key_word in key_words:\n",
    "    print('search for keyword: ', key_word)\n",
    "    date = time.time() # now\n",
    "    excess_time = True\n",
    "    all_df = pd.DataFrame()\n",
    "    c=1\n",
    "    while excess_time:\n",
    "        if k%60 == 0:\n",
    "            print('Rest for 10 min')\n",
    "            time.sleep(600)\n",
    "            print('Work')\n",
    "         # print iteration count, extended tells us group vs user\n",
    "        g=api.newsfeed.search(q=[key_word],count=200, end_time = date-1, start_time=1,extended=1)\n",
    "        if len(g)>1: # check if g contains data\n",
    "            all_df = pd.concat([all_df,pd.DataFrame(g[1:])])\n",
    "            date=g[-1]['date']\n",
    "        elif len(g) <= 1 and c == 1: # check if there is data\n",
    "            print('No posts with that keyword(s)! and FUCK YOU!!!!')\n",
    "            time.sleep(0.4)\n",
    "            break\n",
    "        elif len(g) <= 1 and c != 1: # check if there are posts eft to scrape\n",
    "            print('No more posts to scrape!')\n",
    "            break\n",
    "\n",
    "        if date<time.time()-desired_time: # check termination condition\n",
    "            excess_time = False\n",
    "        print(c,'iteration')\n",
    "        c+=1\n",
    "        k+=1\n",
    "    all_df['keyword'] = key_word\n",
    "    print(len(all_df))\n",
    "    entire_df = pd.concat([entire_df,all_df])\n",
    "'''    print ('tasks done, now sleeping for 30 seconds')\n",
    "    for i in range(30,0,-1):\n",
    "        time.sleep(1)\n",
    "        print (i)'''\n",
    "print(len(entire_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_df.to_csv(r'D:\\vk_all_keywords_365_days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_id = pd.DataFrame()\n",
    "all_df_new_2=entire_df[entire_df.owner_id>0].reset_index()\n",
    "unique_users = list(set(all_df_new_2['owner_id'].astype(int)))\n",
    "for part in range(int(len(unique_users)/9000)+1):\n",
    "    \n",
    "    # take all positive ids ( user ids , negative ids are group ids)\n",
    "    \n",
    "    all_df_new=unique_users[(part*9000):(1+part)*9000]\n",
    "    \n",
    "    for user_part in range(int(len(all_df_new)/901)+1):\n",
    "    # get all users\n",
    "        all_id_2 = pd.DataFrame(api.users.get(user_ids=all_df_new[(user_part*901):(1+user_part)*901], \n",
    "                                              fields = ['occupation','education',\n",
    "                                                        'universities','bdate',\n",
    "                                                        'city','interests',\n",
    "                                                        'activities','site']))\n",
    "        all_id = pd.concat([all_id,all_id_2])\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    \n",
    "try:     \n",
    "    # fill active users status with valid\n",
    "    all_id['deactivated'].fillna('Valid',inplace=True) \n",
    "    # select all deactivated user ids\n",
    "    deactivated_ids = list(all_id[all_id['deactivated']!='Valid'].uid)\n",
    "\n",
    "    # select all active user posts\n",
    "    active_users = all_df_new_2[-all_df_new_2.owner_id.isin(deactivated_ids)]\n",
    "    active_users_info = all_id[all_id['deactivated']=='Valid']\n",
    "except:\n",
    "    active_users = all_df_new_2  \n",
    "    active_users_info = all_id\n",
    "# merge post info and user info\n",
    "overall_data = active_users.merge(active_users_info, left_on='owner_id', right_on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating a dataframe for dictionary values\n",
    "from tqdm import tqdm\n",
    "new_df = pd.DataFrame(columns = ['user_id','post','sex','Name_Surname',\n",
    "                                 'likes','comments','reposts','platform','date','key_word'])\n",
    "# resetting the index it make circles of 0-200\n",
    "#active_users.reset_index(inplace = True)\n",
    "for i in tqdm(range(len(overall_data))):    \n",
    "    new_df.loc[i,'key_word'] = overall_data.loc[i]['keyword']\n",
    "    new_df.loc[i,'user_id'] = overall_data.user.loc[i]['uid']\n",
    "    new_df.loc[i,'sex'] = overall_data.user.loc[i]['sex']   \n",
    "    new_df.loc[i,'Name_Surname'] = overall_data.user.loc[i]['first_name']+'_'+overall_data.user.loc[i]['last_name']\n",
    "    new_df.loc[i,'post'] = overall_data.text.loc[i]\n",
    "    new_df.loc[i,'likes_count'] = overall_data.likes.loc[i]['count']\n",
    "    new_df.loc[i,'comments_count'] = overall_data.comments.loc[i]['count'] \n",
    "    new_df.loc[i,'reposts_count'] = overall_data.reposts.loc[i]['count']\n",
    "    try:\n",
    "        new_df.loc[i,'platform'] = overall_data.post_source.loc[i]['type']+'_'+overall_data.post_source.loc[i]['platform']\n",
    "    except:\n",
    "        new_df.loc[i,'platform'] = overall_data.post_source.loc[i]['type']\n",
    "    new_df.loc[i,'date'] = datetime.fromtimestamp(overall_data.date.loc[i]).strftime('%Y-%m-%d %H:%M:%S')\n",
    "new_df['sex'] = new_df['sex'].apply(lambda x: 'Female' if x==1 else 'Male' if x==2  else 'Not Specified')\n",
    "#new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the comments of posts\n",
    "def commentscrapper(x):\n",
    "    uid = x['user_id']\n",
    "    key_word = x['key_word']\n",
    "    post = api.wall.search(owner_id = uid, query = key_word)\n",
    "    time.sleep(0.4)\n",
    "    if post[0] == 1:\n",
    "        pid = post[1]['id']\n",
    "        likes = api.likes.getList(type='post', item_id = pid, owner_id = uid)\n",
    "        time.sleep(0.4)\n",
    "        reposts = api.likes.getList(type='post', item_id = pid, owner_id = uid, filter = 'copies')\n",
    "        time.sleep(0.4)\n",
    "        try:           \n",
    "            coms = api.wall.getComments(owner_id = uid, post_id = pid, need_likes = 1)\n",
    "            return {'comments':[post[0],coms[1:]],'users_liked': likes,'users_reposted': reposts}\n",
    "        except:\n",
    "            return {'comments':[post[0],'Access Denied'],'users_liked':likes,'users_reposted': reposts}\n",
    "    elif post[0]==0:\n",
    "        return {'comments':'post not found','users_liked':'post not found','users_reposted': 'post not found'}\n",
    "    else:\n",
    "        try:\n",
    "            my_date = x['date']\n",
    "            post_dates = [datetime.fromtimestamp(y['date']).strftime('%Y-%m-%d %H:%M:%S') for y in post[1:]]\n",
    "            index = post_dates.index(my_date)\n",
    "            try:\n",
    "                pid = post[index+1]['id']\n",
    "                likes = api.likes.getList(type='post', item_id = pid, owner_id = uid)\n",
    "                time.sleep(0.4)\n",
    "                reposts = api.likes.getList(type='post', item_id = pid, owner_id = uid, filter = 'copies')\n",
    "                time.sleep(0.4)\n",
    "                coms = api.wall.getComments(owner_id = uid, post_id = pid, need_likes = 1)\n",
    "                return {'comments':[post[0],coms[1:]],'users_liked':likes,'users_reposted': reposts}\n",
    "            except:\n",
    "                pid = post[index+1]['id']\n",
    "                likes = api.likes.getList(type='post', item_id = pid, owner_id = uid)\n",
    "                time.sleep(0.4)\n",
    "                reposts = api.likes.getList(type='post', item_id = pid, owner_id = uid, filter = 'copies')\n",
    "                time.sleep(0.4)\n",
    "                return {'comments':[post[0],'Access Denied'],'users_liked':likes,'users_reposted': reposts}\n",
    "        except:\n",
    "            return {'comments':'time not in Index','users_liked':'time not in Index','users_reposted': 'time not in Index'}\n",
    "    time.sleep(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm.pandas(tqdm())\n",
    "more_new_df = new_df.progress_apply(commentscrapper,axis = 1)\n",
    "comments_likes_reposts = more_new_df.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat([overall_data,comments_likes_reposts],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(r'D:\\vk_all_keywords_365_days_pretty.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df = final_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 45\n",
    "short_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove posts with more than 300 characters and posts with no characters\n",
    "short_df['post']=short_df.text.apply(lambda x: x if len(x)<300 and len(x) !=0 else 'Too Long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "not_long = short_df[short_df['post']!='Too Long'].reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "list_of_animals = 'кот|кошка|котёнок|котяра|котяры|котяр|котище|котик|собака|пес|собачка|кобель|псина|сука|птица|пташка|птенцы|птенец|щенок'\n",
    "def find_animal(x):\n",
    "    my_list = re.findall(list_of_animals,x)\n",
    "    if len(my_list) == 0:\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df['animal'] = short_df.post.apply(lambda x: True if find_animal(x)==True else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df.to_csv(r'D:\\vk_all_keywords_365_days_short.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
